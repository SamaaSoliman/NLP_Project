{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install langchain langchain_community langchain_huggingface faiss-cpu datasets sentence-transformers transformers langchain-ollama rouge-score\nprint(\"Done\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-05-17T23:11:02.539911Z","iopub.execute_input":"2025-05-17T23:11:02.540191Z","iopub.status.idle":"2025-05-17T23:12:28.780694Z","shell.execute_reply.started":"2025-05-17T23:11:02.540159Z","shell.execute_reply":"2025-05-17T23:12:28.779721Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.22)\nCollecting langchain_community\n  Downloading langchain_community-0.3.24-py3-none-any.whl.metadata (2.5 kB)\nCollecting langchain_huggingface\n  Downloading langchain_huggingface-0.2.0-py3-none-any.whl.metadata (941 bytes)\nCollecting faiss-cpu\n  Downloading faiss_cpu-1.11.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (4.8 kB)\nRequirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.6.0)\nRequirement already satisfied: sentence-transformers in /usr/local/lib/python3.11/dist-packages (3.4.1)\nRequirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.3)\nCollecting langchain-ollama\n  Downloading langchain_ollama-0.3.3-py3-none-any.whl.metadata (1.5 kB)\nCollecting rouge-score\n  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nRequirement already satisfied: langchain-core<1.0.0,>=0.3.49 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.50)\nRequirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.7 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.7)\nRequirement already satisfied: langsmith<0.4,>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.23)\nRequirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.11.4)\nRequirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.40)\nRequirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.32.3)\nRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\nCollecting langchain-core<1.0.0,>=0.3.49 (from langchain)\n  Downloading langchain_core-0.3.60-py3-none-any.whl.metadata (5.8 kB)\nCollecting langchain\n  Downloading langchain-0.3.25-py3-none-any.whl.metadata (7.8 kB)\nRequirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (3.11.18)\nRequirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (9.1.2)\nRequirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (0.6.7)\nCollecting pydantic-settings<3.0.0,>=2.4.0 (from langchain_community)\n  Downloading pydantic_settings-2.9.1-py3-none-any.whl.metadata (3.8 kB)\nCollecting httpx-sse<1.0.0,>=0.4.0 (from langchain_community)\n  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\nRequirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (1.26.4)\nCollecting langchain-text-splitters<1.0.0,>=0.3.8 (from langchain)\n  Downloading langchain_text_splitters-0.3.8-py3-none-any.whl.metadata (1.9 kB)\nRequirement already satisfied: tokenizers>=0.19.1 in /usr/local/lib/python3.11/dist-packages (from langchain_huggingface) (0.21.1)\nRequirement already satisfied: huggingface-hub>=0.30.2 in /usr/local/lib/python3.11/dist-packages (from langchain_huggingface) (0.31.1)\nRequirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (25.0)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.18.0)\nRequirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (19.0.1)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\nRequirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.3)\nRequirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\nRequirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\nCollecting fsspec<=2025.3.0,>=2023.1.0 (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n  Downloading fsspec-2025.3.0-py3-none-any.whl.metadata (11 kB)\nRequirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (2.6.0+cu124)\nRequirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.2.2)\nRequirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.15.2)\nRequirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (11.1.0)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\nCollecting ollama<1.0.0,>=0.4.8 (from langchain-ollama)\n  Downloading ollama-0.4.8-py3-none-any.whl.metadata (4.7 kB)\nRequirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from rouge-score) (1.4.0)\nRequirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (from rouge-score) (3.9.1)\nRequirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from rouge-score) (1.17.0)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.6.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.2)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (25.3.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.6.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.4.3)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (0.3.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.20.0)\nRequirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (3.26.1)\nRequirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (0.9.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.30.2->langchain_huggingface) (4.13.2)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.30.2->langchain_huggingface) (1.1.0)\nRequirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.49->langchain) (1.33)\nCollecting packaging (from faiss-cpu)\n  Downloading packaging-24.2-py3-none-any.whl.metadata (3.2 kB)\nRequirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.28.1)\nRequirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (3.10.16)\nRequirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\nRequirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.26.2->langchain_community) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.26.2->langchain_community) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.26.2->langchain_community) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.26.2->langchain_community) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.26.2->langchain_community) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.26.2->langchain_community) (2.4.1)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\nRequirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\nRequirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.0)\nCollecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain_community)\n  Downloading python_dotenv-1.1.0-py3-none-any.whl.metadata (24 kB)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2.4.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2025.4.26)\nRequirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\nCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.11.0->sentence-transformers)\n  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.11.0->sentence-transformers)\n  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.11.0->sentence-transformers)\n  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.11.0->sentence-transformers)\n  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.11.0->sentence-transformers)\n  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.11.0->sentence-transformers)\n  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\nCollecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers)\n  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.2.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\nRequirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk->rouge-score) (8.1.8)\nRequirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk->rouge-score) (1.5.0)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\nRequirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (4.9.0)\nRequirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.0.7)\nRequirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (0.14.0)\nRequirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.49->langchain) (3.0.0)\nRequirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community) (1.1.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.26.2->langchain_community) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.26.2->langchain_community) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.26.2->langchain_community) (1.3.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.26.2->langchain_community) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.26.2->langchain_community) (2024.2.0)\nRequirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.3.1)\nDownloading langchain_community-0.3.24-py3-none-any.whl (2.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m30.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading langchain-0.3.25-py3-none-any.whl (1.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m36.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading langchain_huggingface-0.2.0-py3-none-any.whl (27 kB)\nDownloading faiss_cpu-1.11.0-cp311-cp311-manylinux_2_28_x86_64.whl (31.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.3/31.3 MB\u001b[0m \u001b[31m54.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading langchain_ollama-0.3.3-py3-none-any.whl (21 kB)\nDownloading fsspec-2025.3.0-py3-none-any.whl (193 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.6/193.6 kB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\nDownloading langchain_core-0.3.60-py3-none-any.whl (437 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m437.9/437.9 kB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading langchain_text_splitters-0.3.8-py3-none-any.whl (32 kB)\nDownloading ollama-0.4.8-py3-none-any.whl (13 kB)\nDownloading packaging-24.2-py3-none-any.whl (65 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.5/65.5 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pydantic_settings-2.9.1-py3-none-any.whl (44 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m29.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m66.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading python_dotenv-1.1.0-py3-none-any.whl (20 kB)\nBuilding wheels for collected packages: rouge-score\n  Building wheel for rouge-score (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for rouge-score: filename=rouge_score-0.1.2-py3-none-any.whl size=24934 sha256=e73cfc988d0c9f06c36ada784d338cd4fe7fb79aa92d8935c6e1cdb8e6ffc126\n  Stored in directory: /root/.cache/pip/wheels/1e/19/43/8a442dc83660ca25e163e1bd1f89919284ab0d0c1475475148\nSuccessfully built rouge-score\nInstalling collected packages: python-dotenv, packaging, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cublas-cu12, httpx-sse, fsspec, nvidia-cusparse-cu12, nvidia-cudnn-cu12, pydantic-settings, ollama, nvidia-cusolver-cu12, langchain-core, langchain-text-splitters, langchain-ollama, langchain, rouge-score, langchain_huggingface, langchain_community, faiss-cpu\n  Attempting uninstall: packaging\n    Found existing installation: packaging 25.0\n    Uninstalling packaging-25.0:\n      Successfully uninstalled packaging-25.0\n  Attempting uninstall: nvidia-nvjitlink-cu12\n    Found existing installation: nvidia-nvjitlink-cu12 12.9.41\n    Uninstalling nvidia-nvjitlink-cu12-12.9.41:\n      Successfully uninstalled nvidia-nvjitlink-cu12-12.9.41\n  Attempting uninstall: nvidia-curand-cu12\n    Found existing installation: nvidia-curand-cu12 10.3.10.19\n    Uninstalling nvidia-curand-cu12-10.3.10.19:\n      Successfully uninstalled nvidia-curand-cu12-10.3.10.19\n  Attempting uninstall: nvidia-cufft-cu12\n    Found existing installation: nvidia-cufft-cu12 11.4.0.6\n    Uninstalling nvidia-cufft-cu12-11.4.0.6:\n      Successfully uninstalled nvidia-cufft-cu12-11.4.0.6\n  Attempting uninstall: nvidia-cublas-cu12\n    Found existing installation: nvidia-cublas-cu12 12.9.0.13\n    Uninstalling nvidia-cublas-cu12-12.9.0.13:\n      Successfully uninstalled nvidia-cublas-cu12-12.9.0.13\n  Attempting uninstall: fsspec\n    Found existing installation: fsspec 2025.3.2\n    Uninstalling fsspec-2025.3.2:\n      Successfully uninstalled fsspec-2025.3.2\n  Attempting uninstall: nvidia-cusparse-cu12\n    Found existing installation: nvidia-cusparse-cu12 12.5.9.5\n    Uninstalling nvidia-cusparse-cu12-12.5.9.5:\n      Successfully uninstalled nvidia-cusparse-cu12-12.5.9.5\n  Attempting uninstall: nvidia-cudnn-cu12\n    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n  Attempting uninstall: nvidia-cusolver-cu12\n    Found existing installation: nvidia-cusolver-cu12 11.7.4.40\n    Uninstalling nvidia-cusolver-cu12-11.7.4.40:\n      Successfully uninstalled nvidia-cusolver-cu12-11.7.4.40\n  Attempting uninstall: langchain-core\n    Found existing installation: langchain-core 0.3.50\n    Uninstalling langchain-core-0.3.50:\n      Successfully uninstalled langchain-core-0.3.50\n  Attempting uninstall: langchain-text-splitters\n    Found existing installation: langchain-text-splitters 0.3.7\n    Uninstalling langchain-text-splitters-0.3.7:\n      Successfully uninstalled langchain-text-splitters-0.3.7\n  Attempting uninstall: langchain\n    Found existing installation: langchain 0.3.22\n    Uninstalling langchain-0.3.22:\n      Successfully uninstalled langchain-0.3.22\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ncesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\nbigframes 1.42.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\ngcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2025.3.0 which is incompatible.\nplotnine 0.14.5 requires matplotlib>=3.8.0, but you have matplotlib 3.7.2 which is incompatible.\npandas-gbq 0.28.0 requires google-api-core<3.0.0dev,>=2.10.2, but you have google-api-core 1.34.1 which is incompatible.\nmlxtend 0.23.4 requires scikit-learn>=1.3.1, but you have scikit-learn 1.2.2 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed faiss-cpu-1.11.0 fsspec-2025.3.0 httpx-sse-0.4.0 langchain-0.3.25 langchain-core-0.3.60 langchain-ollama-0.3.3 langchain-text-splitters-0.3.8 langchain_community-0.3.24 langchain_huggingface-0.2.0 nvidia-cublas-cu12-12.4.5.8 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 ollama-0.4.8 packaging-24.2 pydantic-settings-2.9.1 python-dotenv-1.1.0 rouge-score-0.1.2\nDone\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"# Install ollama\n!curl -fsSL https://ollama.com/install.sh | sh","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-17T23:12:28.784546Z","iopub.execute_input":"2025-05-17T23:12:28.785046Z","iopub.status.idle":"2025-05-17T23:13:09.568802Z","shell.execute_reply.started":"2025-05-17T23:12:28.785010Z","shell.execute_reply":"2025-05-17T23:13:09.567838Z"}},"outputs":[{"name":"stdout","text":">>> Installing ollama to /usr/local\n>>> Downloading Linux amd64 bundle\n############################################################################################# 100.0%########                                                                    29.8% 47.1%####################################################                                68.2%\n>>> Creating ollama user...\n>>> Adding ollama user to video group...\n>>> Adding current user to ollama group...\n>>> Creating ollama systemd service...\n\u001b[1m\u001b[31mWARNING:\u001b[m systemd is not running\n\u001b[1m\u001b[31mWARNING:\u001b[m Unable to detect NVIDIA/AMD GPU. Install lspci or lshw to automatically detect and install GPU dependencies.\n>>> The Ollama API is now available at 127.0.0.1:11434.\n>>> Install complete. Run \"ollama\" from the command line.\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import subprocess\nimport time\n\n# Start the server\nserver_process = subprocess.Popen(['ollama', 'serve'], stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n\n# Give it a moment to start\ntime.sleep(1)\n\n# Now run the client command\nsubprocess.run(['ollama', 'pull', 'llama3'])\n\n\n# Kill the server when done\nserver_process.terminate()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-17T23:19:31.672175Z","iopub.execute_input":"2025-05-17T23:19:31.672731Z","iopub.status.idle":"2025-05-17T23:19:33.055601Z","shell.execute_reply.started":"2025-05-17T23:19:31.672707Z","shell.execute_reply":"2025-05-17T23:19:33.054720Z"}},"outputs":[{"name":"stderr","text":"\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠋ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠙ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠹ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest \u001b[K\npulling 6a0746a1ec1a: 100% ▕██████████████████▏ 4.7 GB                         \u001b[K\npulling 4fa551d4f938: 100% ▕██████████████████▏  12 KB                         \u001b[K\npulling 8ab4849b038c: 100% ▕██████████████████▏  254 B                         \u001b[K\npulling 577073ffcc6c: 100% ▕██████████████████▏  110 B                         \u001b[K\npulling 3f8eb4da87fa: 100% ▕██████████████████▏  485 B                         \u001b[K\nverifying sha256 digest \u001b[K\nwriting manifest \u001b[K\nsuccess \u001b[K\u001b[?25h\u001b[?2026l\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"from datasets import load_dataset\nfrom langchain_community.vectorstores import FAISS\nfrom langchain_community.embeddings import HuggingFaceEmbeddings\nfrom langchain_ollama import OllamaLLM\nfrom langchain_core.prompts import ChatPromptTemplate\nfrom langchain_core.runnables import RunnablePassthrough\nfrom langchain_core.output_parsers import StrOutputParser\nimport json\nimport time\nfrom tqdm import tqdm\nfrom rouge_score import rouge_scorer","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-17T23:19:36.056892Z","iopub.execute_input":"2025-05-17T23:19:36.057195Z","iopub.status.idle":"2025-05-17T23:19:40.923786Z","shell.execute_reply.started":"2025-05-17T23:19:36.057173Z","shell.execute_reply":"2025-05-17T23:19:40.923242Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"# 1. Load the entire SQuAD v2 validation set\ndataset = load_dataset(\"squad_v2\", split=\"validation\")\n\ndataset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-17T23:19:46.060412Z","iopub.execute_input":"2025-05-17T23:19:46.061227Z","iopub.status.idle":"2025-05-17T23:19:48.578136Z","shell.execute_reply.started":"2025-05-17T23:19:46.061194Z","shell.execute_reply":"2025-05-17T23:19:48.577352Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/8.92k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7c5810ddb3f04c3a914ee02dbad138a0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00000-of-00001.parquet:   0%|          | 0.00/16.4M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d99cb0ee3f86412cb41153e937ce9963"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"validation-00000-of-00001.parquet:   0%|          | 0.00/1.35M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9cbff9ab14d844c4ab166c83b1c5862d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/130319 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"51ff59ec1d5147b2acc890dce261b4c7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split:   0%|          | 0/11873 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6e790d27f0d04993a3d650346fa3c7e9"}},"metadata":{}},{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['id', 'title', 'context', 'question', 'answers'],\n    num_rows: 11873\n})"},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"# 2. Prepare documents (context passages)\ndocuments = [item[\"context\"] for item in dataset]\n\n# Remove duplicates\ndocuments = list(set(documents))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-17T23:19:50.717889Z","iopub.execute_input":"2025-05-17T23:19:50.718205Z","iopub.status.idle":"2025-05-17T23:19:51.502285Z","shell.execute_reply.started":"2025-05-17T23:19:50.718183Z","shell.execute_reply":"2025-05-17T23:19:51.501453Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"len(documents)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-17T23:19:51.862991Z","iopub.execute_input":"2025-05-17T23:19:51.863857Z","iopub.status.idle":"2025-05-17T23:19:51.868655Z","shell.execute_reply.started":"2025-05-17T23:19:51.863826Z","shell.execute_reply":"2025-05-17T23:19:51.867922Z"}},"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"1204"},"metadata":{}}],"execution_count":8},{"cell_type":"code","source":"dataset[0]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-17T23:19:56.032846Z","iopub.execute_input":"2025-05-17T23:19:56.033540Z","iopub.status.idle":"2025-05-17T23:19:56.038931Z","shell.execute_reply.started":"2025-05-17T23:19:56.033514Z","shell.execute_reply":"2025-05-17T23:19:56.038289Z"}},"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"{'id': '56ddde6b9a695914005b9628',\n 'title': 'Normans',\n 'context': 'The Normans (Norman: Nourmands; French: Normands; Latin: Normanni) were the people who in the 10th and 11th centuries gave their name to Normandy, a region in France. They were descended from Norse (\"Norman\" comes from \"Norseman\") raiders and pirates from Denmark, Iceland and Norway who, under their leader Rollo, agreed to swear fealty to King Charles III of West Francia. Through generations of assimilation and mixing with the native Frankish and Roman-Gaulish populations, their descendants would gradually merge with the Carolingian-based cultures of West Francia. The distinct cultural and ethnic identity of the Normans emerged initially in the first half of the 10th century, and it continued to evolve over the succeeding centuries.',\n 'question': 'In what country is Normandy located?',\n 'answers': {'text': ['France', 'France', 'France', 'France'],\n  'answer_start': [159, 159, 159, 159]}}"},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"# 3. Use e5 small embeddings\nembeddings = HuggingFaceEmbeddings(\n    model_name=\"intfloat/e5-small\", model_kwargs={\"device\": \"cuda\"}\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-17T23:20:04.027997Z","iopub.execute_input":"2025-05-17T23:20:04.028725Z","iopub.status.idle":"2025-05-17T23:20:36.956077Z","shell.execute_reply.started":"2025-05-17T23:20:04.028699Z","shell.execute_reply":"2025-05-17T23:20:36.955485Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_35/3854753891.py:2: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n  embeddings = HuggingFaceEmbeddings(\n2025-05-17 23:20:15.492494: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1747524015.677342      35 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1747524015.731199      35 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"modules.json:   0%|          | 0.00/387 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"38061078f3b74f5ba53cdfb6fea6a7d3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/68.0k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"28f0a0332e5b4955a2b7d80a238889c3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sentence_bert_config.json:   0%|          | 0.00/57.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d6b18ea415b44a978c2b52475a3213fd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/641 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8618bf3788c44586bd5cad471c7b2c0f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/133M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"56bbccf4fdfe497993e9ef2f4e48cf30"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/362 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e8375d626dd747c9959e7dcfdd2f8a75"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"813859b4c9df4cde8edd9b19cb9cf8c7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6eb5ebffcfd14e9ea164ca3faac14d66"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3161777ed6b149e5b0654707ad6c4bd5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/200 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9ed05851329f4423a54372c04202a12a"}},"metadata":{}}],"execution_count":10},{"cell_type":"code","source":"# 4. Create FAISS in-memory vector store (This will take a couple of minutes)\nvectorstore = FAISS.from_texts(documents, embedding=embeddings)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-17T23:20:58.664626Z","iopub.execute_input":"2025-05-17T23:20:58.665347Z","iopub.status.idle":"2025-05-17T23:21:03.646902Z","shell.execute_reply.started":"2025-05-17T23:20:58.665321Z","shell.execute_reply":"2025-05-17T23:21:03.646319Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"# Retrieve top 5 documents\nretriever = vectorstore.as_retriever(search_kwargs={\"k\": 5})","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-17T23:21:18.820042Z","iopub.execute_input":"2025-05-17T23:21:18.820381Z","iopub.status.idle":"2025-05-17T23:21:18.824274Z","shell.execute_reply.started":"2025-05-17T23:21:18.820359Z","shell.execute_reply":"2025-05-17T23:21:18.823430Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"#5. Initialize the LLM with Llama 3.3 8b model\nllm = OllamaLLM(\n    model=\"llama3\",\n    temperature=0.0,\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-17T23:21:29.897004Z","iopub.execute_input":"2025-05-17T23:21:29.897818Z","iopub.status.idle":"2025-05-17T23:21:30.014882Z","shell.execute_reply.started":"2025-05-17T23:21:29.897782Z","shell.execute_reply":"2025-05-17T23:21:30.014021Z"}},"outputs":[],"execution_count":13},{"cell_type":"markdown","source":"## RAG with zero-shot prompting","metadata":{}},{"cell_type":"code","source":"# 6. Prompt template\nprompt = ChatPromptTemplate.from_messages(\n    [\n        (\n            \"system\",\n            \"Answer the question based only on the following context:\\n{context}, Just type Answer: <YOUR ANSWER>\",\n        ),\n        (\"user\", \"{question}\"),\n    ]\n)\n\ndef format_docs(docs):\n    return \"\\n\\n\".join(doc.page_content for doc in docs)\n    \n# 7. RAG chain\nchain = (\n    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n    | prompt\n    | llm\n    | StrOutputParser()\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-17T23:21:40.592463Z","iopub.execute_input":"2025-05-17T23:21:40.592976Z","iopub.status.idle":"2025-05-17T23:21:40.597888Z","shell.execute_reply.started":"2025-05-17T23:21:40.592953Z","shell.execute_reply":"2025-05-17T23:21:40.597221Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"# 8. Example QA\n\nimport subprocess\nimport time\n\n# Start the server\nserver_process = subprocess.Popen(['ollama', 'serve'], stdout=subprocess.PIPE, stderr=subprocess.PIPE)\ntime.sleep(0.5)\n\nquestion = dataset[0][\"question\"]\nprint(\"Question:\", question)\n\nprint(chain.invoke(question))\n\n# Retrieve and print the top documents for the question\nretrieved_docs = retriever.get_relevant_documents(question)\nprint(\"\\n--- Retrieved Documents ---\")\nfor i, doc in enumerate(retrieved_docs, 1):\n    print(f\"Document {i}:\\n{doc.page_content}\\n\")\n\n# Kill the server when done\nserver_process.terminate()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-17T23:21:43.328702Z","iopub.execute_input":"2025-05-17T23:21:43.329014Z","iopub.status.idle":"2025-05-17T23:21:48.603061Z","shell.execute_reply.started":"2025-05-17T23:21:43.328992Z","shell.execute_reply":"2025-05-17T23:21:48.602155Z"}},"outputs":[{"name":"stdout","text":"Question: In what country is Normandy located?\nAnswer: France\n\n--- Retrieved Documents ---\nDocument 1:\nThe Normans (Norman: Nourmands; French: Normands; Latin: Normanni) were the people who in the 10th and 11th centuries gave their name to Normandy, a region in France. They were descended from Norse (\"Norman\" comes from \"Norseman\") raiders and pirates from Denmark, Iceland and Norway who, under their leader Rollo, agreed to swear fealty to King Charles III of West Francia. Through generations of assimilation and mixing with the native Frankish and Roman-Gaulish populations, their descendants would gradually merge with the Carolingian-based cultures of West Francia. The distinct cultural and ethnic identity of the Normans emerged initially in the first half of the 10th century, and it continued to evolve over the succeeding centuries.\n\nDocument 2:\nIn the course of the 10th century, the initially destructive incursions of Norse war bands into the rivers of France evolved into more permanent encampments that included local women and personal property. The Duchy of Normandy, which began in 911 as a fiefdom, was established by the treaty of Saint-Clair-sur-Epte between King Charles III of West Francia and the famed Viking ruler Rollo, and was situated in the former Frankish kingdom of Neustria. The treaty offered Rollo and his men the French lands between the river Epte and the Atlantic coast in exchange for their protection against further Viking incursions. The area corresponded to the northern part of present-day Upper Normandy down to the river Seine, but the Duchy would eventually extend west beyond the Seine. The territory was roughly equivalent to the old province of Rouen, and reproduced the Roman administrative structure of Gallia Lugdunensis II (part of the former Gallia Lugdunensis).\n\nDocument 3:\nIn 1066, Duke William II of Normandy conquered England killing King Harold II at the Battle of Hastings. The invading Normans and their descendants replaced the Anglo-Saxons as the ruling class of England. The nobility of England were part of a single Normans culture and many had lands on both sides of the channel. Early Norman kings of England, as Dukes of Normandy, owed homage to the King of France for their land on the continent. They considered England to be their most important holding (it brought with it the title of King—an important status symbol).\n\nDocument 4:\nNormandy was the site of several important developments in the history of classical music in the 11th century. Fécamp Abbey and Saint-Evroul Abbey were centres of musical production and education. At Fécamp, under two Italian abbots, William of Volpiano and John of Ravenna, the system of denoting notes by letters was developed and taught. It is still the most common form of pitch representation in English- and German-speaking countries today. Also at Fécamp, the staff, around which neumes were oriented, was first developed and taught in the 11th century. Under the German abbot Isembard, La Trinité-du-Mont became a centre of musical composition.\n\nDocument 5:\nThe customary law of Normandy was developed between the 10th and 13th centuries and survives today through the legal systems of Jersey and Guernsey in the Channel Islands. Norman customary law was transcribed in two customaries in Latin by two judges for use by them and their colleagues: These are the Très ancien coutumier (Very ancient customary), authored between 1200 and 1245; and the Grand coutumier de Normandie (Great customary of Normandy, originally Summa de legibus Normanniae in curia laïcali), authored between 1235 and 1245.\n\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_35/3153424737.py:16: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 1.0. Use :meth:`~invoke` instead.\n  retrieved_docs = retriever.get_relevant_documents(question)\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"# 8. Evaluation on the entire validation dataset\ndef evaluate_rag_system(dataset, chain, sample_size=None, is_cot=False):\n    \"\"\"\n    Evaluate the RAG system on the SQuAD v2 validation dataset.\n\n    Args:\n        dataset: The SQuAD v2 validation dataset\n        chain: The RAG chain to evaluate\n        sample_size: Optional number of samples to evaluate (for testing)\n\n    Returns:\n        Dictionary with evaluation results\n    \"\"\"\n    server_process = subprocess.Popen(['ollama', 'serve'], stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n    time.sleep(0.5)\n    \n    results = []\n    # Track metrics totals\n    total_rouge1 = 0.0\n    total_rouge2 = 0.0\n    total_rougeL = 0.0\n    processed_count = 0\n    \n    # Limit the number of samples if specified\n    if sample_size:\n        eval_dataset = dataset.select(range(sample_size))\n    else:\n        eval_dataset = dataset\n\n    start_time = time.time()\n\n    for item in tqdm(eval_dataset, desc=\"Evaluating\"):\n        question = item[\"question\"]\n        ground_truth_answers = item[\"answers\"][\"text\"]\n        if len(ground_truth_answers) == 0:\n            continue\n        has_answer = len(ground_truth_answers) > 0\n\n        try:\n            # Get prediction from the RAG system\n            prediction = chain.invoke(question)\n            # Calculate ROUGE scores\n            rouge_scores = calculate_rouge_scores(prediction, ground_truth_answers, is_cot)\n\n            # Update totals\n            total_rouge1 += rouge_scores[\"rouge1\"]\n            total_rouge2 += rouge_scores[\"rouge2\"]\n            total_rougeL += rouge_scores[\"rougeL\"]\n            processed_count += 1\n\n            # Store result\n            result = {\n                \"question\": question,\n                \"prediction\": prediction,\n                \"ground_truth_answers\": ground_truth_answers,\n                \"has_answer\": has_answer,\n                \"context\": item[\"context\"],\n                \"rouge_scores\": rouge_scores\n            }\n\n            results.append(result)\n\n        except Exception as e:\n            print(f\"Error processing question: {question}\")\n            print(f\"Error: {str(e)}\")\n\n    total_time = time.time() - start_time\n    avg_time_per_question = (\n        total_time / len(eval_dataset) if len(eval_dataset) > 0 else 0\n    )\n\n    # Calculate average metrics\n    avg_rouge1 = total_rouge1 / processed_count if processed_count > 0 else 0\n    avg_rouge2 = total_rouge2 / processed_count if processed_count > 0 else 0\n    avg_rougeL = total_rougeL / processed_count if processed_count > 0 else 0\n    \n    # Kill the server when done\n    server_process.terminate()\n\n    return {\n        \"results\": results,\n        \"total_samples\": len(eval_dataset),\n        \"processed_samples\": processed_count,\n        \"total_time_seconds\": total_time,\n        \"avg_time_per_question\": avg_time_per_question,\n        \"avg_rouge1\": avg_rouge1,\n        \"avg_rouge2\": avg_rouge2,\n        \"avg_rougeL\": avg_rougeL\n    }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-17T23:21:51.105408Z","iopub.execute_input":"2025-05-17T23:21:51.105960Z","iopub.status.idle":"2025-05-17T23:21:51.114478Z","shell.execute_reply.started":"2025-05-17T23:21:51.105940Z","shell.execute_reply":"2025-05-17T23:21:51.113585Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"def calculate_rouge_scores(prediction, ground_truth_answers, is_cot):\n    \"\"\"Calculate ROUGE scores against all ground truth answers and take the best score.\"\"\"\n    if not ground_truth_answers:  # No answer case\n        return {\"rouge1\": 0.0, \"rouge2\": 0.0, \"rougeL\": 0.0}\n\n    # Initialize ROUGE scorer\n    scorer = rouge_scorer.RougeScorer([\"rouge1\", \"rouge2\", \"rougeL\"])\n\n    # Calculate scores against all ground truth answers\n    best_scores = {\"rouge1\": 0.0, \"rouge2\": 0.0, \"rougeL\": 0.0}\n\n    if is_cot:\n        prediction = \"Answer: \" + prediction.rsplit(\"Answer: \", 1)[-1]\n        \n    for answer in ground_truth_answers:\n        scores = scorer.score(prediction, answer)\n\n        # Update best scores\n        for metric in best_scores:\n            best_scores[metric] = max(best_scores[metric], scores[metric].fmeasure)\n\n    return best_scores","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-17T23:22:01.927650Z","iopub.execute_input":"2025-05-17T23:22:01.928348Z","iopub.status.idle":"2025-05-17T23:22:01.933658Z","shell.execute_reply.started":"2025-05-17T23:22:01.928326Z","shell.execute_reply":"2025-05-17T23:22:01.932534Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"# Run evaluation with a small sample size first (can be adjusted)\nprint(\"\\n--- Starting Evaluation ---\")\nsample_size = 1000\nevaluation_results = evaluate_rag_system(dataset, chain, sample_size)\n\nprint(f\"\\nEvaluation completed on {evaluation_results['processed_samples']} samples\")\nprint(f\"Total time: {evaluation_results['total_time_seconds']:.2f} seconds\")\nprint(\n    f\"Average time per question: {evaluation_results['avg_time_per_question']:.2f} seconds\"\n)\n\nprint(f\"Average ROUGE-1 score: {evaluation_results['avg_rouge1']:.4f}\")\nprint(f\"Average ROUGE-2 score: {evaluation_results['avg_rouge2']:.4f}\")\nprint(f\"Average ROUGE-L score: {evaluation_results['avg_rougeL']:.4f}\")\n\n# Save results to a file\nwith open(\"evaluation_results.json\", \"w\") as f:\n    json.dump(evaluation_results, f, indent=2)\n\nprint(\"Evaluation results saved to evaluation_results.json\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-17T23:22:12.792425Z","iopub.execute_input":"2025-05-17T23:22:12.793105Z","iopub.status.idle":"2025-05-17T23:30:36.646892Z","shell.execute_reply.started":"2025-05-17T23:22:12.793083Z","shell.execute_reply":"2025-05-17T23:30:36.646035Z"}},"outputs":[{"name":"stdout","text":"\n--- Starting Evaluation ---\n","output_type":"stream"},{"name":"stderr","text":"Evaluating: 100%|██████████| 1000/1000 [08:23<00:00,  1.99it/s]","output_type":"stream"},{"name":"stdout","text":"\nEvaluation completed on 498 samples\nTotal time: 503.33 seconds\nAverage time per question: 0.50 seconds\nAverage ROUGE-1 score: 0.5330\nAverage ROUGE-2 score: 0.3284\nAverage ROUGE-L score: 0.5307\nEvaluation results saved to evaluation_results.json\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":18},{"cell_type":"markdown","source":"## RAG with Chain of thoughts (CoT) prompt","metadata":{}},{"cell_type":"code","source":"# 6. Prompt template\nprompt = ChatPromptTemplate.from_messages(\n    [\n        (\n            \"system\",\n            \"\"\"Answer the question based only on the following context:\n                {context}\n                \n                To answer correctly, please follow these steps:\n                1. Read the context carefully\n                2. Identify the key information in the context that relates to the question\n                3. Reason step by step to find the answer\n                4. Provide your final answer clearly prefixed with \"Answer: \"\n                \n                You MUST structure your response as follows:\n                Thinking: [Write out your step-by-step reasoning process here, analyzing the context to find relevant information]\n                Answer: [Your concise final answer]\n                \n                Example:\n                Context: The Normans (Norman: Nourmands; French: Normands; Latin: Normanni) were the people who in the 10th and 11th centuries gave their name to Normandy, a region in France. They were descended from Norse (\"Norman\" comes from \"Norseman\") raiders and pirates from Denmark, Iceland and Norway who, under their leader Rollo, agreed to swear fealty to King Charles III of West Francia.\n                \n                Question: In what country is Normandy located?\n                \n                Thinking: The context directly states that Normandy is \"a region in France.\" This clearly indicates that Normandy is located within the country of France. There's no ambiguity in the text about this fact.\n                \n                Answer: France\n                \"\"\",\n        ),\n        (\"user\", \"{question}\"),\n    ]\n)\n\ndef format_docs(docs):\n    return \"\\n\\n\".join(doc.page_content for doc in docs)\n    \n# 7. RAG chain\nchain = (\n    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n    | prompt\n    | llm\n    | StrOutputParser()\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-17T23:30:54.364288Z","iopub.execute_input":"2025-05-17T23:30:54.364594Z","iopub.status.idle":"2025-05-17T23:30:54.370648Z","shell.execute_reply.started":"2025-05-17T23:30:54.364570Z","shell.execute_reply":"2025-05-17T23:30:54.369887Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"# 8. Example QA\n\nimport subprocess\nimport time\n\n# Start the server\nserver_process = subprocess.Popen(['ollama', 'serve'], stdout=subprocess.PIPE, stderr=subprocess.PIPE)\ntime.sleep(0.5)\n\nquestion = dataset[0][\"question\"]\nprint(\"Question:\", question)\n\nprint(chain.invoke(question))\n\n# Retrieve and print the top documents for the question\nretrieved_docs = retriever.get_relevant_documents(question)\nprint(\"\\n--- Retrieved Documents ---\")\nfor i, doc in enumerate(retrieved_docs, 1):\n    print(f\"Document {i}:\\n{doc.page_content}\\n\")\n\n# Kill the server when done\nserver_process.terminate()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-17T23:30:54.631053Z","iopub.execute_input":"2025-05-17T23:30:54.631372Z","iopub.status.idle":"2025-05-17T23:31:01.809635Z","shell.execute_reply.started":"2025-05-17T23:30:54.631351Z","shell.execute_reply":"2025-05-17T23:31:01.808688Z"}},"outputs":[{"name":"stdout","text":"Question: In what country is Normandy located?\nThinking: According to the context, Normandy is described as a region in France. The Duchy of Normandy was established by Rollo and King Charles III of West Francia, and it was situated in the former Frankish kingdom of Neustria. This suggests that Normandy is located within the country of France.\n\nAnswer: France\n\n--- Retrieved Documents ---\nDocument 1:\nThe Normans (Norman: Nourmands; French: Normands; Latin: Normanni) were the people who in the 10th and 11th centuries gave their name to Normandy, a region in France. They were descended from Norse (\"Norman\" comes from \"Norseman\") raiders and pirates from Denmark, Iceland and Norway who, under their leader Rollo, agreed to swear fealty to King Charles III of West Francia. Through generations of assimilation and mixing with the native Frankish and Roman-Gaulish populations, their descendants would gradually merge with the Carolingian-based cultures of West Francia. The distinct cultural and ethnic identity of the Normans emerged initially in the first half of the 10th century, and it continued to evolve over the succeeding centuries.\n\nDocument 2:\nIn the course of the 10th century, the initially destructive incursions of Norse war bands into the rivers of France evolved into more permanent encampments that included local women and personal property. The Duchy of Normandy, which began in 911 as a fiefdom, was established by the treaty of Saint-Clair-sur-Epte between King Charles III of West Francia and the famed Viking ruler Rollo, and was situated in the former Frankish kingdom of Neustria. The treaty offered Rollo and his men the French lands between the river Epte and the Atlantic coast in exchange for their protection against further Viking incursions. The area corresponded to the northern part of present-day Upper Normandy down to the river Seine, but the Duchy would eventually extend west beyond the Seine. The territory was roughly equivalent to the old province of Rouen, and reproduced the Roman administrative structure of Gallia Lugdunensis II (part of the former Gallia Lugdunensis).\n\nDocument 3:\nIn 1066, Duke William II of Normandy conquered England killing King Harold II at the Battle of Hastings. The invading Normans and their descendants replaced the Anglo-Saxons as the ruling class of England. The nobility of England were part of a single Normans culture and many had lands on both sides of the channel. Early Norman kings of England, as Dukes of Normandy, owed homage to the King of France for their land on the continent. They considered England to be their most important holding (it brought with it the title of King—an important status symbol).\n\nDocument 4:\nNormandy was the site of several important developments in the history of classical music in the 11th century. Fécamp Abbey and Saint-Evroul Abbey were centres of musical production and education. At Fécamp, under two Italian abbots, William of Volpiano and John of Ravenna, the system of denoting notes by letters was developed and taught. It is still the most common form of pitch representation in English- and German-speaking countries today. Also at Fécamp, the staff, around which neumes were oriented, was first developed and taught in the 11th century. Under the German abbot Isembard, La Trinité-du-Mont became a centre of musical composition.\n\nDocument 5:\nThe customary law of Normandy was developed between the 10th and 13th centuries and survives today through the legal systems of Jersey and Guernsey in the Channel Islands. Norman customary law was transcribed in two customaries in Latin by two judges for use by them and their colleagues: These are the Très ancien coutumier (Very ancient customary), authored between 1200 and 1245; and the Grand coutumier de Normandie (Great customary of Normandy, originally Summa de legibus Normanniae in curia laïcali), authored between 1235 and 1245.\n\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"# Run evaluation with a small sample size first (can be adjusted)\nprint(\"\\n--- Starting Evaluation ---\")\nsample_size = 1000\nevaluation_results = evaluate_rag_system(dataset, chain, sample_size, is_cot=True)\n\nprint(f\"\\nEvaluation completed on {evaluation_results['processed_samples']} samples\")\nprint(f\"Total time: {evaluation_results['total_time_seconds']:.2f} seconds\")\nprint(\n    f\"Average time per question: {evaluation_results['avg_time_per_question']:.2f} seconds\"\n)\n\nprint(f\"Average ROUGE-1 score: {evaluation_results['avg_rouge1']:.4f}\")\nprint(f\"Average ROUGE-2 score: {evaluation_results['avg_rouge2']:.4f}\")\nprint(f\"Average ROUGE-L score: {evaluation_results['avg_rougeL']:.4f}\")\n\n# Save results to a file\nwith open(\"evaluation_results_cot.json\", \"w\") as f:\n    json.dump(evaluation_results, f, indent=2)\n\nprint(\"Evaluation results saved to evaluation_results.json\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-17T23:31:01.810862Z","iopub.execute_input":"2025-05-17T23:31:01.811607Z","iopub.status.idle":"2025-05-17T23:59:36.712413Z","shell.execute_reply.started":"2025-05-17T23:31:01.811577Z","shell.execute_reply":"2025-05-17T23:59:36.711419Z"}},"outputs":[{"name":"stdout","text":"\n--- Starting Evaluation ---\n","output_type":"stream"},{"name":"stderr","text":"Evaluating: 100%|██████████| 1000/1000 [28:34<00:00,  1.71s/it]","output_type":"stream"},{"name":"stdout","text":"\nEvaluation completed on 498 samples\nTotal time: 1714.38 seconds\nAverage time per question: 1.71 seconds\nAverage ROUGE-1 score: 0.5202\nAverage ROUGE-2 score: 0.2876\nAverage ROUGE-L score: 0.5193\nEvaluation results saved to evaluation_results.json\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":21},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}